## helper train/fit function
import torch
import torch.optim as optim
import torch.nn as nn
from ax.plot.contour import plot_contour
from ax.plot.trace import optimization_trace_single_method
from ax import optimize
from ax.utils.notebook.plotting import render, init_notebook_plotting

def Train(model, HyperParams, trainloader):
    optimizer = optim.SGD(model.parameters(),
                          lr=HyperParams["learn_rate"],
                          momentum=HyperParams["momentum"])



def train(net, parameterization, trainloader):
    optimizer = optim.SGD(net.parameters(),
                          lr=parameterization["lr"], # 学习率
                          momentum=parameterization["momentum"])
    criterion = nn.CrossEntropyLoss()

    for epoch in range(2):  # loop over the dataset multiple times

        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data

            # zero the parameter gradients
            optimizer.zero_grad()

            # forward + backward + optimize
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()
            if i % 2000 == 1999:  # print every 2000 mini-batches
                print('[%d, %5d] loss: %.3f' %
                      (epoch + 1, i + 1, running_loss / 2000))
                running_loss = 0.0

    return net


## helper function to evaluate the accuracy for the tested model
def evaluate(net, testloader):
    correct = 0
    total = 0
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print('Accuracy of the network on the 10000 test images: %d %%' % (
            100 * correct / total))
    return 100 * correct / total

Tuple[Dict[str, Union[str, bool, float, int, None]],
      Optional[Tuple[Dict[str, float], Optional[Dict[str, Dict[str, float]]]]],
      Experiment,
      Optional[ModelBridge]]


## helper function train-evaluate to pass as the function to be optimized
def train_evaluate(parameterization):
    net = Net()
    net = train(net, parameterization, trainloader)
    return evaluate(net, testloader)

best_parameters, values, experiment, model = optimize(
    parameters=[
        {"name": "learn_rate", "type": "range", "bounds": [8e-6, 1e-3], "log_scale": True},
        {"name": "dropout_rate", "type": "range", "bounds": [0.0, 0.9]},
        {"name": "rnn_layers", "type": "range", "bounds": [1, 10]}
    ],
    evaluation_function=train_evaluate,
    objective_name='accuracy',
    total_trials=15
)